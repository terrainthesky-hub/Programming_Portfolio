<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head=""></title><link rel="preload" href="/Programming_Portfolio/_next/static/css/86a3f3b21e687f7f.css" as="style"/><link rel="stylesheet" href="/Programming_Portfolio/_next/static/css/86a3f3b21e687f7f.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/Programming_Portfolio/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/Programming_Portfolio/_next/static/chunks/webpack-58b9165375ff94a3.js" defer=""></script><script src="/Programming_Portfolio/_next/static/chunks/framework-2f335d22a7318891.js" defer=""></script><script src="/Programming_Portfolio/_next/static/chunks/main-6be06e882e0908a3.js" defer=""></script><script src="/Programming_Portfolio/_next/static/chunks/pages/_app-c44db3626848d2ae.js" defer=""></script><script src="/Programming_Portfolio/_next/static/chunks/pages/blog/%5Bid%5D-61e3eb6444c7f5e3.js" defer=""></script><script src="/Programming_Portfolio/_next/static/7ABlkba1gZGjbyqCpZ9Fb/_buildManifest.js" defer=""></script><script src="/Programming_Portfolio/_next/static/7ABlkba1gZGjbyqCpZ9Fb/_ssgManifest.js" defer=""></script></head><body class="antialiased"><div id="__next"><div class="flex flex-col min-h-screen bg-gray-50 text-gray-800"><header class="bg-white/80 backdrop-blur-md sticky top-0 z-50 shadow-md"><nav class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><div class="flex-shrink-0"><a class="text-2xl font-bold text-gray-900 hover:text-indigo-600 transition-colors" href="/Programming_Portfolio">Your Name</a></div><div class="hidden md:block"><div class="ml-10 flex items-baseline space-x-4"><a class="text-gray-600 hover:text-indigo-500 px-3 py-2 rounded-md text-sm font-medium" href="/Programming_Portfolio">Home</a><a class="text-gray-600 hover:text-indigo-500 px-3 py-2 rounded-md text-sm font-medium" href="/Programming_Portfolio/blog">Blog</a></div></div></div></nav></header><main class="flex-grow container mx-auto px-4 sm:px-6 lg:px-8"><article class="max-w-3xl mx-auto py-12"><div class="bg-white p-8 md:p-12 rounded-lg shadow-lg"><h1 class="text-4xl font-extrabold text-gray-900 mb-2"></h1><p class="text-gray-500 mb-8"></p><div class="prose lg:prose-xl max-w-none"><p>I followed this guide on how to solve the KNN algorithm: https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/</p>
<p>KNearestNeighbors is essentially just finding the things that are closest in distance.</p>
<p>The KNearestNeighbors algorithm is fairly simple to make without libraries, you find the euclidiean distance by subtracting the first iterated
row by the target we want to find closest. After that we square the number and find the square root to avoid negative numbers.
In the simplest sense we are, subtracting every row by the target to find which row is closest distance to the target.</p>
<pre><code>  def euclidiean_distance(row1, row2):
      distance = 0.0
      for i in range(len(row1)-1):
	  distance += (row1[i] - row2[i])**2
      return sqrt(distance)
      
 
</code></pre>
<p>Doing the rest without libraries is a lot trickier. To get the neighbors you need to append the distances to a list so they're
stored in memory then you sort the distances with a custom key so that the second item in the tuple is used in sorting. Finally,
you create another list and iterate the distances based on how many number of neighbors you want returned.</p>
<pre><code>def get_neighbors(train, test_row, num_neighbors):
      distances = list()
      for train_row in train:
	  dist = euclidiean_distance(test_row, train_row)
	  distances.append((train_row, dist))         
      distances.sort(key=lambda tup: tup[1])
      neighbors = list()
      for i in range(num_neighbors):
	  neighbors.append(distances[i][0])
      return neighbors
</code></pre>
<p>Then finally we can get the neighbors of a point in the dataset by selecting how many neighbors we want:</p>
<pre><code>  dataset = [[2.7810836,2.550537003,0],
	[1.465489372,2.362125076,0],
	[3.396561688,4.400293529,0],
	[1.38807019,1.850220317,0],
	[3.06407232,3.005305973,0],
	[7.627531214,2.759262235,1],
	[5.332441248,2.088626775,1],
	[6.922596716,1.77106367,1],
	[8.675418651,-0.242068655,1],
	[7.673756466,3.508563011,1]]

  neighbors = get_neighbors(dataset, dataset[0], 3)

  for neighbor in neighbors:
      print(neighbor)

 We get an output of:
  [4.6, 3.1, 1.5, 0.2, 2]
  [4.6, 3.2, 1.4, 0.2, 2]
  [4.7, 3.2, 1.6, 0.2, 2]
</code></pre>
<p>To predict a class based on KNN, we iterate through the class row in neighbors, then we find the max() of that which returns
the largest number. The max() function takes a set of unique class values and calls the count on the list of class values for each class value in the set.</p>
<pre><code>def predict_classification(train, test_row, num_neighbors):
    neighbors = get_neighbors(train, test_row, num_neighbors)
    output_values = [row[-1] for row in neighbors]
    prediction = max(set(output_values), key=output_values.count)
    return prediction

prediction = predict_classification(dataset, dataset[0], 3)
print('Expected %d, Got %d.' % (dataset[0][-1], prediction))
Expected 2, Got 2.
</code></pre>
</div></div></article></main><footer class="bg-white border-t mt-12 py-6"><div class="container mx-auto px-4 sm:px-6 lg:px-8 text-center text-gray-500"><p>Â© <!-- -->2025<!-- --> Your Name. All Rights Reserved.</p><div class="flex justify-center space-x-4 mt-2"><a href="https://github.com/terrainthesky-hub" target="_blank" rel="noopener noreferrer" class="hover:text-indigo-500">GitHub</a><a href="https://linkedin.com/in/lesley-rich-86bb8572/" target="_blank" rel="noopener noreferrer" class="hover:text-indigo-500">LinkedIn</a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"2020-9-24-KNN algorithm breakdown","contentHtml":"\u003cp\u003eI followed this guide on how to solve the KNN algorithm: https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/\u003c/p\u003e\n\u003cp\u003eKNearestNeighbors is essentially just finding the things that are closest in distance.\u003c/p\u003e\n\u003cp\u003eThe KNearestNeighbors algorithm is fairly simple to make without libraries, you find the euclidiean distance by subtracting the first iterated\nrow by the target we want to find closest. After that we square the number and find the square root to avoid negative numbers.\nIn the simplest sense we are, subtracting every row by the target to find which row is closest distance to the target.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e  def euclidiean_distance(row1, row2):\n      distance = 0.0\n      for i in range(len(row1)-1):\n\t  distance += (row1[i] - row2[i])**2\n      return sqrt(distance)\n      \n \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDoing the rest without libraries is a lot trickier. To get the neighbors you need to append the distances to a list so they're\nstored in memory then you sort the distances with a custom key so that the second item in the tuple is used in sorting. Finally,\nyou create another list and iterate the distances based on how many number of neighbors you want returned.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef get_neighbors(train, test_row, num_neighbors):\n      distances = list()\n      for train_row in train:\n\t  dist = euclidiean_distance(test_row, train_row)\n\t  distances.append((train_row, dist))         \n      distances.sort(key=lambda tup: tup[1])\n      neighbors = list()\n      for i in range(num_neighbors):\n\t  neighbors.append(distances[i][0])\n      return neighbors\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen finally we can get the neighbors of a point in the dataset by selecting how many neighbors we want:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e  dataset = [[2.7810836,2.550537003,0],\n\t[1.465489372,2.362125076,0],\n\t[3.396561688,4.400293529,0],\n\t[1.38807019,1.850220317,0],\n\t[3.06407232,3.005305973,0],\n\t[7.627531214,2.759262235,1],\n\t[5.332441248,2.088626775,1],\n\t[6.922596716,1.77106367,1],\n\t[8.675418651,-0.242068655,1],\n\t[7.673756466,3.508563011,1]]\n\n  neighbors = get_neighbors(dataset, dataset[0], 3)\n\n  for neighbor in neighbors:\n      print(neighbor)\n\n We get an output of:\n  [4.6, 3.1, 1.5, 0.2, 2]\n  [4.6, 3.2, 1.4, 0.2, 2]\n  [4.7, 3.2, 1.6, 0.2, 2]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo predict a class based on KNN, we iterate through the class row in neighbors, then we find the max() of that which returns\nthe largest number. The max() function takes a set of unique class values and calls the count on the list of class values for each class value in the set.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef predict_classification(train, test_row, num_neighbors):\n    neighbors = get_neighbors(train, test_row, num_neighbors)\n    output_values = [row[-1] for row in neighbors]\n    prediction = max(set(output_values), key=output_values.count)\n    return prediction\n\nprediction = predict_classification(dataset, dataset[0], 3)\nprint('Expected %d, Got %d.' % (dataset[0][-1], prediction))\nExpected 2, Got 2.\n\u003c/code\u003e\u003c/pre\u003e\n"}},"__N_SSG":true},"page":"/blog/[id]","query":{"id":"2020-9-24-KNN algorithm breakdown"},"buildId":"7ABlkba1gZGjbyqCpZ9Fb","assetPrefix":"/Programming_Portfolio","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>